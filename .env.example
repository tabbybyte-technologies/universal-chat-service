PORT=3000
API_KEY=change-me
LLAMA_BASE_URL_DOCKER=http://llama-cpp:8080/v1
LLAMA_BASE_URL_HOST=http://host.docker.internal:8080/v1
LLAMA_MODEL=local-model
LLAMA_API_KEY=dummy
LLAMA_IMAGE=ghcr.io/ggml-org/llama.cpp:server
LLAMA_PLATFORM=linux/amd64
LLAMA_MODEL_FILE=model.gguf
LLAMA_CTX_SIZE=4096
LLAMA_PARALLEL=1
